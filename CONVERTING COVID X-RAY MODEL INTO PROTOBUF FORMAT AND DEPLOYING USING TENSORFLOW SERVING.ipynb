{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TDXD7CxrANSA"
   },
   "source": [
    "# IMPORTING THE REQUIREMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "60v2urUvANme"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nQiSWJmuAzD-"
   },
   "source": [
    "# LINKING TO THE DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JEyHhs3KAzXW",
    "outputId": "87910797-f674-4284-a1d8-b0297987cd1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bhyE6eHqBJGE",
    "outputId": "ed50f580-753c-41e6-e6dd-631bd9cbb521"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/CovidDataset\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/My Drive/CovidDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tKGlWnqVBTO1",
    "outputId": "71e12720-3a80-479f-9fb5-f75aa3655011"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covid19.jpeg  Covid_xray_model.h5  normal_1.jpg  normal.jpg  Train  Validation\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "brVOdVhJAp_G"
   },
   "source": [
    "# LOADING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AWFfd3E5Ao8p"
   },
   "outputs": [],
   "source": [
    "model = load_model(\"Covid_xray_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r2bm2O8TBcqu"
   },
   "source": [
    "# SAMPLE PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "6dv9kcDsBYWC",
    "outputId": "16355fdc-e699-41b0-d716-da6192a9af91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Normal\n"
     ]
    }
   ],
   "source": [
    "img = image.load_img(\"Validation/Normal/NORMAL2-IM-0601-0001.jpeg\", target_size=(224, 224))\n",
    "img = image.img_to_array(img)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "\n",
    "pred = model.predict_classes(img)\n",
    "\n",
    "print(pred[0, 0])\n",
    "\n",
    "if pred == 1:\n",
    "  print(\"Normal\")\n",
    "elif pred == 0:\n",
    "  print(\"Covid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cjYOSqXzET6M"
   },
   "source": [
    "# SAVING THE ENTIRE MODEL TO PROTOBUF FORMAT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "C29lnyH-Bnr2",
    "outputId": "89d20633-286f-4177-8f9f-c152d76b481a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export_path = /tmp/1\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: /tmp/1/assets\n",
      "\n",
      "Saved model:\n",
      "total 228\n",
      "drwxr-xr-x 2 root root   4096 Jul 31 18:08 assets\n",
      "-rw-r--r-- 1 root root 222809 Jul 31 18:08 saved_model.pb\n",
      "drwxr-xr-x 2 root root   4096 Jul 31 18:08 variables\n"
     ]
    }
   ],
   "source": [
    "MODEL_DIR = tempfile.gettempdir()\n",
    "version = 1\n",
    "export_path = os.path.join(MODEL_DIR, str(version))\n",
    "print('export_path = {}\\n'.format(export_path))\n",
    "\n",
    "tf.keras.models.save_model(\n",
    "    model,\n",
    "    export_path,\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format=None,\n",
    "    signatures=None,\n",
    "    options=None\n",
    ")\n",
    "\n",
    "print('\\nSaved model:')\n",
    "!ls -l {export_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I3XXEiuoEkGT"
   },
   "source": [
    "# EXAMINING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "fH7NFhQ_D2DV",
    "outputId": "7550fa36-4d5d-4cf8-9cfc-77f5b5ed0b6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['__saved_model_init_op']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['__saved_model_init_op'] tensor_info:\n",
      "        dtype: DT_INVALID\n",
      "        shape: unknown_rank\n",
      "        name: NoOp\n",
      "  Method name is: \n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['conv2d_8_input'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 224, 224, 3)\n",
      "        name: serving_default_conv2d_8_input:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['dense_5'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 1)\n",
      "        name: StatefulPartitionedCall:0\n",
      "  Method name is: tensorflow/serving/predict\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0731 18:09:34.146137 140285786208128 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling __init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "\n",
      "Defined Functions:\n",
      "  Function Name: '__call__'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=u'inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          conv2d_8_input: TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=u'conv2d_8_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          conv2d_8_input: TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=u'conv2d_8_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=u'inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "\n",
      "  Function Name: '_default_save_signature'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          conv2d_8_input: TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=u'conv2d_8_input')\n",
      "\n",
      "  Function Name: 'call_and_return_all_conditional_losses'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=u'inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=u'inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          conv2d_8_input: TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=u'conv2d_8_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          conv2d_8_input: TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=u'conv2d_8_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir {export_path} --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B7l3ckwiEpjD"
   },
   "source": [
    "# ADDING TENSORFLOW SERVING DISTRIBUTION API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "colab_type": "code",
    "id": "e1a9p5CVEJTi",
    "outputId": "a3f26a6e-485c-4e67-ae66-12c0cbe8d7a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "100  2943  100  2943    0     0  18393      0 --:--:-- --:--:-- --:--:-- 18393\n",
      "OK\n",
      "Get:1 http://storage.googleapis.com/tensorflow-serving-apt stable InRelease [3,012 B]\n",
      "Get:2 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
      "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:4 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
      "Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
      "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
      "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
      "Get:10 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server-universal amd64 Packages [349 B]\n",
      "Get:11 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
      "Get:12 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 Packages [341 B]\n",
      "Get:13 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
      "Get:17 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,851 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [27.2 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,413 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [116 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,334 kB]\n",
      "Get:22 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [893 kB]\n",
      "Fetched 5,910 kB in 3s (1,877 kB/s)\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "37 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
     ]
    }
   ],
   "source": [
    "!echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
    "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n",
    "!apt update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vP8j6DMqE51f"
   },
   "source": [
    "# INSTALLING TENSORFLOW SERVING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "colab_type": "code",
    "id": "RBL_HKGZE3kx",
    "outputId": "4a8bcd48-874b-4509-9c6e-64e403c93e1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-440\n",
      "Use 'apt autoremove' to remove it.\n",
      "The following NEW packages will be installed:\n",
      "  tensorflow-model-server\n",
      "0 upgraded, 1 newly installed, 0 to remove and 37 not upgraded.\n",
      "Need to get 187 MB of archives.\n",
      "After this operation, 0 B of additional disk space will be used.\n",
      "Get:1 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 tensorflow-model-server all 2.2.0 [187 MB]\n",
      "Fetched 187 MB in 3s (68.6 MB/s)\n",
      "Selecting previously unselected package tensorflow-model-server.\n",
      "(Reading database ... 144487 files and directories currently installed.)\n",
      "Preparing to unpack .../tensorflow-model-server_2.2.0_all.deb ...\n",
      "Unpacking tensorflow-model-server (2.2.0) ...\n",
      "Setting up tensorflow-model-server (2.2.0) ...\n"
     ]
    }
   ],
   "source": [
    "! apt-get install tensorflow-model-server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-D64I-VjFNha"
   },
   "source": [
    "# SERVING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GzDxEuzjFDe7"
   },
   "outputs": [],
   "source": [
    "os.environ[\"MODEL_DIR\"] = MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MqEyLm84FRr-",
    "outputId": "17bf1025-851a-4734-8f09-b1512adc97e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting job # 0 in a separate thread.\n"
     ]
    }
   ],
   "source": [
    "%%bash --bg \n",
    "nohup tensorflow_model_server \\\n",
    "  --rest_api_port=8501 \\\n",
    "  --model_name=covid19_Xray_model \\\n",
    "  --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "colab_type": "code",
    "id": "fbGUG7wxFYqA",
    "outputId": "3269422d-94ef-4420-c59c-cc6bd5090f12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-31 18:14:56.209571: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-07-31 18:14:56.230165: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:234] Restoring SavedModel bundle.\n",
      "2020-07-31 18:14:56.321864: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:183] Running initialization op on SavedModel bundle at path: /tmp/1\n",
      "2020-07-31 18:14:56.334054: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:364] SavedModel load for tags { serve }; Status: success: OK. Took 128571 microseconds.\n",
      "2020-07-31 18:14:56.335802: I tensorflow_serving/servables/tensorflow/saved_model_warmup.cc:105] No warmup data file found at /tmp/1/assets.extra/tf_serving_warmup_requests\n",
      "2020-07-31 18:14:56.336143: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: covid19_Xray_model version: 1}\n",
      "2020-07-31 18:14:56.337447: I tensorflow_serving/model_servers/server.cc:355] Running gRPC ModelServer at 0.0.0.0:8500 ...\n",
      "[warn] getaddrinfo: address family for nodename not supported\n",
      "[evhttp_server.cc : 238] NET_LOG: Entering the event loop ...\n",
      "2020-07-31 18:14:56.338579: I tensorflow_serving/model_servers/server.cc:375] Exporting HTTP/REST API at:localhost:8501 ...\n"
     ]
    }
   ],
   "source": [
    "!tail server.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ecv75XJlF6ec"
   },
   "source": [
    "# MAKE A REQUEST TO THE MODEL FOR PREDICTION IN TENSORFLOW SERVING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "QeUA2DwuGF7r",
    "outputId": "55206b76-307f-4593-871c-015e555fc50f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Covid\n"
     ]
    }
   ],
   "source": [
    "img = image.load_img(\"covid19.jpeg\", target_size=(224, 224))\n",
    "img = image.img_to_array(img)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "\n",
    "pred = model.predict_classes(img)\n",
    "\n",
    "print(pred[0, 0])\n",
    "\n",
    "if pred == 1:\n",
    "  print(\"Normal\")\n",
    "elif pred == 0:\n",
    "  print(\"Covid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qtN0aQf7FcVF"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": img.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Bz2ym_4HGLEk",
    "outputId": "307c2955-5fae-4a08-928e-602e39ae4083"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covid\n"
     ]
    }
   ],
   "source": [
    "!pip install -q requests\n",
    "\n",
    "import requests\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "json_response = requests.post('http://localhost:8501/v1/models/covid19_Xray_model:predict', data=data, headers=headers)\n",
    "predictions = json.loads(json_response.text)['predictions']\n",
    "\n",
    "if predictions == [[1.0]]:\n",
    "  print(\"Normal\")\n",
    "elif predictions == [[0.0]]:\n",
    "  print(\"Covid\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Covid19_Xray_Model_Tensorflow_Serving.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
